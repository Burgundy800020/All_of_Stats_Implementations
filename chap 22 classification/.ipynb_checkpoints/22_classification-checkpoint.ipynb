{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8c6ba33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chapter 22\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.stats as scp\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40c725da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.142</td>\n",
       "      <td>3</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.555</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.404</td>\n",
       "      <td>6</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.147</td>\n",
       "      <td>5</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.250</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4601 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2    3     4     5     6     7     8     9   ...     48  \\\n",
       "0     0.00  0.64  0.64  0.0  0.32  0.00  0.00  0.00  0.00  0.00  ...  0.000   \n",
       "1     0.21  0.28  0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94  ...  0.000   \n",
       "2     0.06  0.00  0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25  ...  0.010   \n",
       "3     0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.000   \n",
       "4     0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.000   \n",
       "...    ...   ...   ...  ...   ...   ...   ...   ...   ...   ...  ...    ...   \n",
       "4596  0.31  0.00  0.62  0.0  0.00  0.31  0.00  0.00  0.00  0.00  ...  0.000   \n",
       "4597  0.00  0.00  0.00  0.0  0.00  0.00  0.00  0.00  0.00  0.00  ...  0.000   \n",
       "4598  0.30  0.00  0.30  0.0  0.00  0.00  0.00  0.00  0.00  0.00  ...  0.102   \n",
       "4599  0.96  0.00  0.00  0.0  0.32  0.00  0.00  0.00  0.00  0.00  ...  0.000   \n",
       "4600  0.00  0.00  0.65  0.0  0.00  0.00  0.00  0.00  0.00  0.00  ...  0.000   \n",
       "\n",
       "         49   50     51     52     53     54   55    56  57  \n",
       "0     0.000  0.0  0.778  0.000  0.000  3.756   61   278   1  \n",
       "1     0.132  0.0  0.372  0.180  0.048  5.114  101  1028   1  \n",
       "2     0.143  0.0  0.276  0.184  0.010  9.821  485  2259   1  \n",
       "3     0.137  0.0  0.137  0.000  0.000  3.537   40   191   1  \n",
       "4     0.135  0.0  0.135  0.000  0.000  3.537   40   191   1  \n",
       "...     ...  ...    ...    ...    ...    ...  ...   ...  ..  \n",
       "4596  0.232  0.0  0.000  0.000  0.000  1.142    3    88   0  \n",
       "4597  0.000  0.0  0.353  0.000  0.000  1.555    4    14   0  \n",
       "4598  0.718  0.0  0.000  0.000  0.000  1.404    6   118   0  \n",
       "4599  0.057  0.0  0.000  0.000  0.000  1.147    5    78   0  \n",
       "4600  0.000  0.0  0.125  0.000  0.000  1.250    5    40   0  \n",
       "\n",
       "[4601 rows x 58 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 4601\n",
    "k = 58\n",
    "colNames = [i for i in range(k)]\n",
    "data = pd.read_csv('data/spam.txt', delim_whitespace = True, names=colNames)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8763b912",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data[k-1].to_numpy()\n",
    "X = data[[i for i in range(k-1)]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f2d942",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "faca4967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6059552271245382"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n1 = Y.sum()\n",
    "n0 = n-n1\n",
    "pi1 = n1/n\n",
    "pi0 = n0/n\n",
    "pi0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df94e92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0da5e1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X0 = X[[Y[i]==0 for i in range(n)]]\n",
    "X1 = X[[Y[i]==1 for i in range(n)]]\n",
    "mu0 = np.mean(X0, axis=0)\n",
    "mu1 = np.mean(X1, axis=0)\n",
    "S0 = np.mean( np.array([np.outer(X0[i]-mu0, X0[i]-mu0) for i in range(n0)]) , axis=0)\n",
    "S1 = np.mean( np.array([np.outer(X1[i]-mu1, X1[i]-mu1) for i in range(n1)]) , axis=0)\n",
    "S = 1/n*(n0*S0 + n1*S1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5945443",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LDA(X, Y, pi0, pi1, mu0, mu1, S, summarize=False):\n",
    "    n, k = X.shape\n",
    "    Sinv = np.linalg.inv(S)\n",
    "    Yhat = np.zeros(n)\n",
    "    summary = np.zeros((2, 2),dtype=np.int64)\n",
    "    for i in range(n):\n",
    "        delta0 = np.log(pi0) + X[i].dot(Sinv).dot(mu0)-1/2*mu0.dot(Sinv).dot(mu0)\n",
    "        delta1 = np.log(pi1) + X[i].dot(Sinv).dot(mu1)-1/2*mu1.dot(Sinv).dot(mu1) \n",
    "        Yhat[i] = delta0 < delta1\n",
    "        summary[int(delta0 < delta1)][Y[i]] +=1\n",
    "    trainingErr = (summary[0][1] + summary[1][0])/n\n",
    "    if(summarize):\n",
    "        print(summary)\n",
    "    return Yhat, trainingErr\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9307de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2663  387]\n",
      " [ 125 1426]]\n",
      "0.11128015648772006\n"
     ]
    }
   ],
   "source": [
    "Yhat, trainingErr = LDA(X, Y, pi0, pi1, mu0, mu1, S, summarize=True)\n",
    "print(trainingErr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a87b61c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7e7fdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def QDA(X, Y, pi0, pi1, mu0, mu1, S0, S1, summarize=False):\n",
    "    n, k = X.shape\n",
    "    Sinv0 = np.linalg.inv(S0)\n",
    "    Sinv1 = np.linalg.inv(S1)\n",
    "    Det0 = np.linalg.det(S0)\n",
    "    Det1 = np.linalg.det(S1)\n",
    "    Yhat = np.zeros(n)\n",
    "    summary = np.zeros((2, 2),dtype=np.int64)\n",
    "    for i in range(n):\n",
    "        delta0 = np.log(pi0) -1/2*np.log(Det0) -1/2*(X[i]-mu0).dot(Sinv0).dot(X[i]-mu0)\n",
    "        delta1 = np.log(pi1) -1/2*np.log(Det1) -1/2*(X[i]-mu1).dot(Sinv1).dot(X[i]-mu1)\n",
    "        Yhat[i] = delta0 < delta1\n",
    "        summary[int(delta0 < delta1)][Y[i]] +=1\n",
    "    trainingErr = (summary[0][1] + summary[1][0])/n\n",
    "    if(summarize):\n",
    "        print(summary)\n",
    "    return Yhat, trainingErr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c19baf8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2101   82]\n",
      " [ 687 1731]]\n",
      "0.16713757878722016\n"
     ]
    }
   ],
   "source": [
    "Yhat, trainingErr=QDA(X, Y, pi0, pi1, mu0, mu1, S0, S1, summarize=True)\n",
    "print(trainingErr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e97a9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f91ef57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiLinearFit(X, W, Y):\n",
    "    n, k = X.shape\n",
    "    beta = None\n",
    "    try:\n",
    "        beta = np.linalg.inv(X.transpose().dot(W).dot(X)).dot(X.transpose()).dot(W).dot(Y)\n",
    "    except:\n",
    "        print(X)\n",
    "    Yhat = X.dot(beta)\n",
    "    trainingErr = np.sum((Y-Yhat)**2)\n",
    "    sig = (trainingErr/(n-k))**0.5\n",
    "    seMatrix = sig**2*np.linalg.inv(X.transpose().dot(X))\n",
    "    return beta, sig, seMatrix, trainingErr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7afa9dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticFit(X, Y, maxIter=1000, summarize=False):\n",
    "    n, k = X.shape\n",
    "    beta = np.zeros(shape=k)\n",
    "    \n",
    "    def logit(x):\n",
    "        return np.log(x/1-x)\n",
    "    def logitInv(x):\n",
    "        return 1/(np.exp(-x)+1)\n",
    "    \n",
    "    Z = np.zeros(shape=n)\n",
    "    p = np.zeros(shape=n)\n",
    "    seMatrix = None\n",
    "    for _ in range(maxIter):\n",
    "        for i in range(n):\n",
    "            p[i] = logitInv(beta.dot(X[i]))\n",
    "            Z[i] = beta.dot(X[i]) + (Y[i]-p[i])/(p[i]*(1-p[i]))\n",
    "        W = np.diag([float(p[i])*(1-p[i]) for i in range(n)])\n",
    "        beta, sig, seMatrix, trainingErr = multiLinearFit(X, W, Z)\n",
    "    \n",
    "    Zhat = X.dot(beta)\n",
    "    phat = logitInv(Zhat)\n",
    "    print(beta)\n",
    "    if summarize:\n",
    "        summary = np.zeros((2, 2),dtype=np.int64)\n",
    "        for i in range(n):\n",
    "            summary[int(phat[i]>0.5)][Y[i]] += 1\n",
    "        print(summary)\n",
    "    trainingErrRate = np.mean(np.array([(phat[i]<0.5 and Y[i]==1) or (phat[i]>0.5 and Y[i]==0) for i in range(n)]))       \n",
    "    return beta, seMatrix, trainingErrRate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b8af5ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.12152966e-01 -2.51599870e-01 -1.74818676e-02  2.09030196e-01\n",
      "  3.70323569e-01  3.49693104e-01  2.13604777e+00  4.22927887e-01\n",
      "  3.38327504e-01  1.64665215e-02  2.86678602e-02 -3.63782844e-01\n",
      " -3.51516270e-01 -9.09309609e-02  8.51206727e-01  6.09655789e-01\n",
      "  7.44149013e-01  8.44672819e-02 -7.17359249e-02  7.30268020e-01\n",
      "  1.31093267e-01  2.93226841e-01  2.16453502e+00  6.06011832e-01\n",
      " -1.30493100e+00 -8.03446895e-01 -7.34833072e-01  4.06377936e-01\n",
      " -7.19154808e-01 -3.86588302e-01 -1.66292476e-01  1.28134949e+00\n",
      " -1.18666351e+00 -2.80196325e-01 -7.15371781e-01  3.53369483e-01\n",
      " -2.25041370e-01 -6.31391435e-01 -6.58789869e-01 -4.73270385e-01\n",
      " -1.23868207e+00 -1.40819021e+00 -9.83265689e-01 -1.59394817e+00\n",
      " -9.05504601e-01 -1.47822231e+00 -2.13168844e+00 -2.32771378e+00\n",
      " -1.62681523e+00 -1.42028211e+00 -2.65326193e+00  2.62175913e-01\n",
      "  4.64852676e+00  1.17192568e+00 -6.73430199e-03  3.96031719e-03\n",
      "  2.91420428e-04]\n",
      "[[2560  143]\n",
      " [ 228 1670]]\n",
      "0.08063464464246903\n"
     ]
    }
   ],
   "source": [
    "beta, seMatrix, trainingErrRate = logisticFit(X, Y, maxIter=4, summarize=True)\n",
    "print(trainingErrRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4ecfd6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross validate LDA and logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "550f1519",
   "metadata": {},
   "outputs": [],
   "source": [
    "V = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a73fe761",
   "metadata": {},
   "outputs": [],
   "source": [
    "m=n//V\n",
    "indices = np.arange(V*m)\n",
    "permIndices = np.random.choice(indices, V*m, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cbf9a669",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xperm = X2[permIndices]\n",
    "Yperm = Y[permIndices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "00b519e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xcv = Xperm.copy().reshape( (V, m, k2))\n",
    "Ycv = Yperm.copy().reshape((V, m))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86571465",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b555e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b375f62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LDA_train(X, Y):\n",
    "    n, k = X.shape\n",
    "    n1 = Y.sum()\n",
    "    n0 = n-n1\n",
    "    pi1 = n1/n\n",
    "    pi0 = n0/n\n",
    "    X0 = X[[Y[i]==0 for i in range(n)]]\n",
    "    X1 = X[[Y[i]==1 for i in range(n)]]\n",
    "    mu0 = np.mean(X0, axis=0)\n",
    "    mu1 = np.mean(X1, axis=0)\n",
    "    S0 = np.mean( np.array([np.outer(X0[i]-mu0, X0[i]-mu0) for i in range(n0)]) , axis=0)\n",
    "    S1 = np.mean( np.array([np.outer(X1[i]-mu1, X1[i]-mu1) for i in range(n1)]) , axis=0)\n",
    "    S = 1/n*(n0*S0 + n1*S1)\n",
    "    return pi0, pi1, mu0, mu1, S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3623792e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LDA_test(X, Y, pi0, pi1, mu0, mu1, S, summarize=False):\n",
    "    n, k = X.shape\n",
    "    Sinv = np.linalg.inv(S)\n",
    "    Yhat = np.zeros(n)\n",
    "    summary = np.zeros((2, 2),dtype=np.int64)\n",
    "    for i in range(n):\n",
    "        delta0 = np.log(pi0) + X[i].dot(Sinv).dot(mu0)-1/2*mu0.dot(Sinv).dot(mu0)\n",
    "        delta1 = np.log(pi1) + X[i].dot(Sinv).dot(mu1)-1/2*mu1.dot(Sinv).dot(mu1) \n",
    "        Yhat[i] = delta0 < delta1\n",
    "        summary[int(delta0 < delta1)][Y[i]] +=1\n",
    "    testErr = (summary[0][1] + summary[1][0])/n\n",
    "    if(summarize):\n",
    "        print(summary)\n",
    "    return Yhat, testErr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "294d4ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11369565217391304"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errs = np.zeros(V)\n",
    "for v in range(V):\n",
    "    Xtr = Xperm[ [i < v*m or i >= (v+1)*m for i in range(V*m)] ]\n",
    "    Ytr = Yperm[ [i < v*m or i >= (v+1)*m for i in range(V*m)] ]\n",
    "    pi0, pi1, mu0, mu1, S = LDA_train(Xtr, Ytr)\n",
    "    Yhat, testErr = LDA_test(Xcv[v], Ycv[v], pi0, pi1, mu0, mu1, S)\n",
    "    errs[v] = testErr\n",
    "errs.mean() #cross validation err rate for LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "77ef06bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12478260869565219"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errs = np.zeros(V)\n",
    "for v in range(V):\n",
    "    Xtr = Xperm[ [i < v*m or i >= (v+1)*m for i in range(V*m)] ]\n",
    "    Ytr = Yperm[ [i < v*m or i >= (v+1)*m for i in range(V*m)] ]\n",
    "    pi0, pi1, mu0, mu1, S = LDA_train(Xtr, Ytr)\n",
    "    Yhat, testErr = LDA_test(Xcv[v], Ycv[v], pi0, pi1, mu0, mu1, S)\n",
    "    errs[v] = testErr\n",
    "errs.mean() #cross validation err rate for LDA with reduced number of covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f5eba674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13152174, 0.12934783, 0.11956522, 0.11413043, 0.12934783])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "719f1258",
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f1238b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_train(X, Y, maxIter=1000):\n",
    "    n, k = X.shape\n",
    "    beta = np.zeros(shape=k)\n",
    "    \n",
    "    def logit(x):\n",
    "        return np.log(x/1-x)\n",
    "    def logitInv(x):\n",
    "        return 1/(np.exp(-x)+1)\n",
    "    \n",
    "    Z = np.zeros(shape=n)\n",
    "    p = np.zeros(shape=n)\n",
    "    seMatrix = None\n",
    "    for _ in range(maxIter):\n",
    "        for i in range(n):\n",
    "            p[i] = logitInv(beta.dot(X[i]))\n",
    "            Z[i] = beta.dot(X[i]) + (Y[i]-p[i])/(p[i]*(1-p[i]))\n",
    "        W = np.diag([float(p[i])*(1-p[i]) for i in range(n)])\n",
    "        beta, sig, seMatrix, trainingErr = multiLinearFit(X, W, Z)\n",
    "    return beta, sig, seMatrix\n",
    "\n",
    "def logistic_test(X, Y, beta, summarize=False):\n",
    "    n, k = X.shape\n",
    "    def logit(x):\n",
    "        return np.log(x/1-x)\n",
    "    def logitInv(x):\n",
    "        return 1/(np.exp(-x)+1)\n",
    "    Zhat = X.dot(beta)\n",
    "    phat = logitInv(Zhat)\n",
    "    if summarize:\n",
    "        summary = np.zeros((2, 2),dtype=np.int64)\n",
    "        for i in range(n):\n",
    "            summary[int(phat[i]>0.5)][Y[i]] += 1\n",
    "        print(summary)\n",
    "    testErrRate = np.mean(np.array([(phat[i]<0.5 and Y[i]==1) or (phat[i]>0.5 and Y[i]==0) for i in range(n)]))       \n",
    "    return phat, testErrRate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f7136283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13195652173913044"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errs = np.zeros(V)\n",
    "for v in range(V):\n",
    "    Xtr = Xperm[ [i < v*m or i >= (v+1)*m for i in range(V*m)] ]\n",
    "    Ytr = Yperm[ [i < v*m or i >= (v+1)*m for i in range(V*m)] ]\n",
    "    beta, sig, seMatrix = logistic_train(Xtr, Ytr, maxIter = 4)\n",
    "    Yhat, testErr = logistic_test(Xcv[v], Ycv[v], beta)\n",
    "    errs[v] = testErr\n",
    "errs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4374f174",
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose best 10 covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7a7c47ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def WaldStats(j):\n",
    "    diff = np.abs(mu0[j]-mu1[j])\n",
    "    se = (S0[j][j]/n0 + S1[j][j]/n1)**0.5\n",
    "    return diff/se\n",
    "\n",
    "k = 57\n",
    "k2 = 30\n",
    "W = [WaldStats(j) for j in range(k)]\n",
    "bestCov = []\n",
    "for val in sorted(W)[::-1]:\n",
    "    bestCov.append(W.index(val))\n",
    "\n",
    "bestCov = bestCov[0:k2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "20a43d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = X[:,bestCov]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "981b148c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2664  444]\n",
      " [ 124 1369]]\n",
      "0.12345142360356444\n"
     ]
    }
   ],
   "source": [
    "pi0t, pi1t, mu0t, mu1t, St = LDA_train(X2, Y)\n",
    "Yhat, testErr = LDA_test(X2, Y, pi0t, pi1t, mu0t, mu1t, St, summarize=True)\n",
    "print(testErr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "da7d2421",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta, sig, seMatrix = logistic_train(X2, Y, maxIter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "99e22bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2403  243]\n",
      " [ 385 1570]]\n",
      "0.13018908932840687\n"
     ]
    }
   ],
   "source": [
    "phat, testErrRate  = logistic_test(X2, Y, beta, summarize=True)\n",
    "print(testErrRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7b78377",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6264fd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.svm as svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc6d3e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel=\"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91ff03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c476c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
